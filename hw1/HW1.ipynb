{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5954a625-cc4d-45ea-a999-779929975543",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "### Task 1\n",
    "We are going to be using Logistic Regression in order to attempt to solve the problem of sentiment analysis. While this may not be the absolute best approach to this topic, I believe that it will do a sufficient job. This is because many individual words are highly correlated to the sentiment of the overall statement. For example the word \"Amazing\" being somewhere in a movie review typically indicates that it is a good review. If we take a bag of words approach to the problem the linear model can assign high weights to positive words and low weights to negative words thus allowing a basic way of assigning sentiment. This method failes to capture temporal and interword relations. For example \"I really wished that the movie would be great, however this was not true\" is a more intricate example that probably will not be well classified by this approach to the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcadbf0-2be4-425f-a319-7a8c3e2fde3c",
   "metadata": {},
   "source": [
    "## Data Analysis / Visualization\n",
    "### Task 2\n",
    "Dataset: http://ai.stanford.edu/~amaas/data/sentiment/ \\\n",
    "We are attempting to see how correlated certain words are to the sentiment of a positive movie review. To do this we will collect a count of the total occurences of certain words in positive examples as well as their total counts in the dataset overall. The graph below demonstrates that the occurences of certain individual words can be used to reason about how positive a certain review is. While using a bag of words approach to sentiment analysis takes away the temporal relationship between words logistic regression may well be a good method for simple examples as well as a good possible baseline for future models on this topic. We also remove words that have less than 100 total occurences in the dataset. This should allow the parameters of the model to be based off of words which we have sufficent data to reason about. It also prevents over-fitting to certain phrases that appear with low frequency, for example if \"iiiii\" appears once and the one apperance is of positive sentiment then Gradient Descent may make the weight related to this word extremely high so that all future occurences of this word are also classified as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836215ad-87f0-446a-9799-97e94dd1e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1076dd35-ff6a-4d90-a151-f4e488659b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_WORDS = 2000\n",
    "PROVIDED_VOCAB_PATH = \"/home/lenny/Documents/PROGRAMMING/CSCI4967/hw1/aclImdb/imdb.vocab\"\n",
    "VOCAB_PATH = \"/home/lenny/Documents/PROGRAMMING/CSCI4967/hw1/vocab.txt\"\n",
    "TRAIN_PATH = \"/home/lenny/Documents/PROGRAMMING/CSCI4967/hw1/aclImdb/train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a5b84d-7d99-447c-8a47-f43a01e9ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Construct a vocabulary using the top N words\n",
    "f = open(PROVIDED_VOCAB_PATH, 'r')\n",
    "vocab = f.readlines()[:TOP_N_WORDS]\n",
    "vocab_list = [word.strip() for word in vocab]\n",
    "word_index = { vocab_list[i] : i for i in range(len(vocab_list)) }\n",
    "#print(word_index)\n",
    "#print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84fe353-20a3-4de4-bcc2-e175ee7fd095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Updated Vocab (Remove Words with low occurence rate)\n",
    "#Collect the total amount of % of times each word was seen in a postive/negative review\n",
    "#score = total_pos_appearences/ total_apperances\n",
    "POS_PATH = os.path.join(TRAIN_PATH, \"pos\")\n",
    "NEG_PATH = os.path.join(TRAIN_PATH, \"neg\")\n",
    "POSITIVE_EXAMPLES = os.listdir(POS_PATH)\n",
    "NEGATIVE_EXAMPLES = os.listdir(NEG_PATH)\n",
    "total_count = [0 for _ in range(len(vocab))]\n",
    "positive_count = [0 for _ in range(len(vocab))]\n",
    "for file in POSITIVE_EXAMPLES:\n",
    "    f = open(os.path.join(POS_PATH, file), 'r')\n",
    "    example = f.read().strip()\n",
    "    example = example.translate(str.maketrans('','',string.punctuation))\n",
    "    example = example.split()\n",
    "    for word in example:\n",
    "        if word in word_index:\n",
    "            total_count[word_index[word]]+=1\n",
    "            positive_count[word_index[word]]+=1\n",
    "    f.close()\n",
    "    \n",
    "for file in NEGATIVE_EXAMPLES:\n",
    "    f = open(os.path.join(NEG_PATH, file), 'r')\n",
    "    example = f.read().strip()\n",
    "    example = example.translate(str.maketrans('','',string.punctuation))\n",
    "    example = example.split()\n",
    "    for word in example:\n",
    "        if word in word_index:\n",
    "            total_count[word_index[word]]+=1\n",
    "    f.close()\n",
    "    \n",
    "scores = [0.5 if total < 100 else pos/total for pos,total in zip(positive_count, total_count)]\n",
    "#print(scores)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f990b60a-a3f0-45f5-a14d-18032b1ca063",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find Top 15 words \n",
    "zipped_index = sorted([(score, index) for index,score in zip(range(len(scores)), scores)], key=lambda x: (-x[0], -x[1]))\n",
    "zipped_index = zipped_index[:7] + zipped_index[-7:]\n",
    "#print(zipped_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be39a4ac-c6d1-49b9-a131-ae062f11d977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [vocab_list[item[1]] for item in zipped_index]\n",
    "y = [item[0] for item in zipped_index]\n",
    "plt.bar(x,y)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea07de34-97fe-4a12-8f1f-f611c3bf1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Words with less than 100 occurences\n",
    "temp = []\n",
    "for i, count in enumerate(total_count):\n",
    "    if count >= 100:\n",
    "        temp.append(vocab[i])\n",
    "\n",
    "vocab = temp\n",
    "word_index = { vocab_list[i] : i for i in range(len(vocab)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b54b589-ce59-4954-b5de-de002549bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset using updated vocab \n",
    "DSET = []\n",
    "for file in POSITIVE_EXAMPLES:\n",
    "    f = open(os.path.join(POS_PATH, file), 'r')\n",
    "    example = f.read().strip()\n",
    "    example = example.translate(str.maketrans('','',string.punctuation))\n",
    "    example = example.split()\n",
    "    wc = [0 for _ in range(len(vocab))]\n",
    "    for word in example:\n",
    "        if word in word_index:\n",
    "            wc[word_index[word]]+=1\n",
    "    DSET.append((wc, 1))\n",
    "    f.close()\n",
    "    \n",
    "for file in NEGATIVE_EXAMPLES:\n",
    "    f = open(os.path.join(NEG_PATH, file), 'r')\n",
    "    example = f.read().strip()\n",
    "    example = example.translate(str.maketrans('','',string.punctuation))\n",
    "    example = example.split()\n",
    "    wc = [0 for _ in range(len(vocab))]\n",
    "    for word in example:\n",
    "        if word in word_index:\n",
    "            wc[word_index[word]]+=1\n",
    "    DSET.append((wc, 0))\n",
    "    f.close()\n",
    "    \n",
    "random.shuffle(DSET)\n",
    "#print(len(DSET))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188c63e0-62e3-4762-8ffa-1af84c5be3fc",
   "metadata": {},
   "source": [
    "## Implementing Logistic Regression\n",
    "### Task 3\n",
    "Now we are going to try and implement logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cccfc792-b39d-427d-bdf4-e0e155d43fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "    \n",
    "def loss(X, Y_hat, Y):\n",
    "    n = X.shape[1]\n",
    "    eps = 1e-4\n",
    "    loss = (-1/n) * np.sum( Y*np.log(Y_hat+ eps) + (1-Y)*np.log(1-Y_hat+ eps) )\n",
    "    dW = (1/n) * X@(Y_hat-Y).T\n",
    "    dB = (1/n) * np.sum(Y_hat - Y)\n",
    "    return loss, dW, dB\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, num_features):\n",
    "        self.W = np.random.normal(size=(num_features, 1))\n",
    "        self.b = 0\n",
    "    def __call__(self, X):\n",
    "        return sigmoid(self.W.T@X + self.b)\n",
    "#x = np.random.normal(size=(10,3))\n",
    "#print(lm(x))\n",
    "#loss(x, lm(x), np.array([[1, 1, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24c95399-bb25-477a-a022-70a912e8b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyper Parameters\n",
    "EPOCHS = 1000\n",
    "batch_size = 2048\n",
    "lr = .1\n",
    "lr_decay = .99\n",
    "lm = LogisticRegression(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12f8dbb8-b1b1-4d95-b50b-a496a8e6de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Loss:  0.0016293133098917673\n",
      "Running Loss:  0.0015313883288025224\n",
      "Running Loss:  0.0014485483303216583\n",
      "Running Loss:  0.0013858329011725778\n",
      "Running Loss:  0.001329655064405285\n",
      "Running Loss:  0.0012792257361414904\n",
      "Running Loss:  0.0012390847130416814\n",
      "Running Loss:  0.0012024896777544716\n",
      "Running Loss:  0.0011676630568028545\n",
      "Running Loss:  0.0011350991290849034\n",
      "Running Loss:  0.0011060736838440566\n",
      "Running Loss:  0.0010792205893091643\n",
      "Running Loss:  0.0010548845397803119\n",
      "Running Loss:  0.0010332970969069097\n",
      "Running Loss:  0.001013594852362617\n",
      "Running Loss:  0.0009955495851688215\n",
      "Running Loss:  0.000978570498739279\n",
      "Running Loss:  0.0009623873808229389\n",
      "Running Loss:  0.0009470821517287885\n",
      "Running Loss:  0.0009326122395720962\n",
      "Running Loss:  0.0009187905546099689\n",
      "Running Loss:  0.0009054748766926828\n",
      "Running Loss:  0.0008926224614055553\n",
      "Running Loss:  0.000880248585229479\n",
      "Running Loss:  0.0008683701258937168\n",
      "Running Loss:  0.0008569903906348884\n",
      "Running Loss:  0.0008461060969131387\n",
      "Running Loss:  0.0008357142112087158\n",
      "Running Loss:  0.0008257938559009057\n",
      "Running Loss:  0.0008162957746930498\n",
      "Running Loss:  0.0008071693567233541\n",
      "Running Loss:  0.0007983733426812363\n",
      "Running Loss:  0.0007898736884796128\n",
      "Running Loss:  0.0007816437729055264\n",
      "Running Loss:  0.0007736645759390939\n",
      "Running Loss:  0.0007659231402531012\n",
      "Running Loss:  0.0007584104560954526\n",
      "Running Loss:  0.0007511196080130444\n",
      "Running Loss:  0.0007440443437886628\n",
      "Running Loss:  0.000737178195681852\n",
      "Running Loss:  0.0007305141799764083\n",
      "Running Loss:  0.0007240448688534144\n",
      "Running Loss:  0.0007177625861936898\n",
      "Running Loss:  0.0007116596036005611\n",
      "Running Loss:  0.0007057283279833124\n",
      "Running Loss:  0.0006999615115759179\n",
      "Running Loss:  0.0006943524950249661\n",
      "Running Loss:  0.0006888954379323334\n",
      "Running Loss:  0.0006835854316887905\n",
      "Running Loss:  0.000678418386215378\n",
      "Running Loss:  0.0006733906818070115\n",
      "Running Loss:  0.0006684987277995159\n",
      "Running Loss:  0.0006637386327947854\n",
      "Running Loss:  0.0006591061031444788\n",
      "Running Loss:  0.0006545965433891493\n",
      "Running Loss:  0.0006502052567458759\n",
      "Running Loss:  0.0006459276530490172\n",
      "Running Loss:  0.000641759413098731\n",
      "Running Loss:  0.0006376965916053601\n",
      "Running Loss:  0.0006337356578063962\n",
      "Running Loss:  0.0006298734799464919\n",
      "Running Loss:  0.0006261072639067234\n",
      "Running Loss:  0.000622434460362531\n",
      "Running Loss:  0.0006188526587673304\n",
      "Running Loss:  0.0006153594882663844\n",
      "Running Loss:  0.0006119525432154081\n",
      "Running Loss:  0.0006086293437181909\n",
      "Running Loss:  0.0006053873315654624\n",
      "Running Loss:  0.0006022238930814608\n",
      "Running Loss:  0.0005991363959885386\n",
      "Running Loss:  0.0005961222281540208\n",
      "Running Loss:  0.000593178830120817\n",
      "Running Loss:  0.0005903037179937282\n",
      "Running Loss:  0.0005874944967435219\n",
      "Running Loss:  0.0005847488657907734\n",
      "Running Loss:  0.0005820646192033787\n",
      "Running Loss:  0.0005794396425974864\n",
      "Running Loss:  0.0005768719083497583\n",
      "Running Loss:  0.0005743594702525165\n",
      "Running Loss:  0.0005719004583406554\n",
      "Running Loss:  0.0005694930742831052\n",
      "Running Loss:  0.0005671355874545085\n",
      "Running Loss:  0.0005648263316032337\n",
      "Running Loss:  0.0005625637019388632\n",
      "Running Loss:  0.0005603461524837021\n",
      "Running Loss:  0.0005581721936363158\n",
      "Running Loss:  0.0005560403900175191\n",
      "Running Loss:  0.0005539493587472837\n",
      "Running Loss:  0.0005518977682991299\n",
      "Running Loss:  0.0005498843379996605\n",
      "Running Loss:  0.0005479078381179653\n",
      "Running Loss:  0.0005459670903660839\n",
      "Running Loss:  0.0005440609685444528\n",
      "Running Loss:  0.0005421883990359923\n",
      "Running Loss:  0.0005403483608804911\n",
      "Running Loss:  0.0005385398852354169\n",
      "Running Loss:  0.0005367620541289186\n",
      "Running Loss:  0.0005350139985135904\n",
      "Running Loss:  0.0005332948957167316\n",
      "Running Loss:  0.0005316039664427018\n",
      "Running Loss:  0.0005299404715112486\n",
      "Running Loss:  0.0005283037085149783\n",
      "Running Loss:  0.0005266930085563098\n",
      "Running Loss:  0.0005251077331878541\n",
      "Running Loss:  0.0005235472716385906\n",
      "Running Loss:  0.0005220110383682195\n",
      "Running Loss:  0.0005204984709580087\n",
      "Running Loss:  0.00051900902832091\n",
      "Running Loss:  0.000517542189196936\n",
      "Running Loss:  0.000516097450891493\n",
      "Running Loss:  0.0005146743282126338\n",
      "Running Loss:  0.0005132723525665797\n",
      "Running Loss:  0.0005118910711769529\n",
      "Running Loss:  0.0005105300464009174\n",
      "Running Loss:  0.0005091888551227472\n",
      "Running Loss:  0.0005078670882118614\n",
      "Running Loss:  0.0005065643500371959\n",
      "Running Loss:  0.0005052802580327155\n",
      "Running Loss:  0.0005040144423102114\n",
      "Running Loss:  0.000502766545315178\n",
      "Running Loss:  0.0005015362215202648\n",
      "Running Loss:  0.0005003231371487599\n",
      "Running Loss:  0.0004991269699184742\n",
      "Running Loss:  0.0004979474087944829\n",
      "Running Loss:  0.0004967841537381647\n",
      "Running Loss:  0.0004956369154396845\n",
      "Running Loss:  0.0004945054150222164\n",
      "Running Loss:  0.0004933893837081456\n",
      "Running Loss:  0.0004922885624407274\n",
      "Running Loss:  0.0004912027014582518\n",
      "Running Loss:  0.0004901315598219754\n",
      "Running Loss:  0.0004890749049028593\n",
      "Running Loss:  0.0004880325118356045\n",
      "Running Loss:  0.00048700416295108077\n",
      "Running Loss:  0.0004859896471996607\n",
      "Running Loss:  0.000484988759578577\n",
      "Running Loss:  0.00048400130057569266\n",
      "Running Loss:  0.00048302707564076185\n",
      "Running Loss:  0.0004820658946931421\n",
      "Running Loss:  0.0004811175716725532\n",
      "Running Loss:  0.0004801819241369901\n",
      "Running Loss:  0.00047925877290950526\n",
      "Running Loss:  0.0004783479417734847\n",
      "Running Loss:  0.0004774492572143631\n",
      "Running Loss:  0.0004765625482043959\n",
      "Running Loss:  0.0004756876460262798\n",
      "Running Loss:  0.00047482438413093463\n",
      "Running Loss:  0.0004739725980246105\n",
      "Running Loss:  0.0004731321251805994\n",
      "Running Loss:  0.0004723028049711559\n",
      "Running Loss:  0.00047148447861563355\n",
      "Running Loss:  0.0004706769891413461\n",
      "Running Loss:  0.0004698801813542206\n",
      "Running Loss:  0.00046909390181676115\n",
      "Running Loss:  0.00046831799883137833\n",
      "Running Loss:  0.0004675523224275485\n",
      "Running Loss:  0.00046679672435165186\n",
      "Running Loss:  0.00046605105805862636\n",
      "Running Loss:  0.00046531517870491377\n",
      "Running Loss:  0.00046458894314227727\n",
      "Running Loss:  0.000463872209912328\n",
      "Running Loss:  0.00046316483924163513\n",
      "Running Loss:  0.00046246669303741714\n",
      "Running Loss:  0.00046177763488385514\n",
      "Running Loss:  0.00046109753003905046\n",
      "Running Loss:  0.0004604262454327107\n",
      "Running Loss:  0.0004597636496645798\n",
      "Running Loss:  0.0004591096130036539\n",
      "Running Loss:  0.000458464007388129\n",
      "Running Loss:  0.0004578267064260923\n",
      "Running Loss:  0.0004571975853968151\n",
      "Running Loss:  0.0004565765212525939\n",
      "Running Loss:  0.00045596339262097375\n",
      "Running Loss:  0.0004553580798072088\n",
      "Running Loss:  0.00045476046479678354\n",
      "Running Loss:  0.0004541704312578272\n",
      "Running Loss:  0.00045358786454321716\n",
      "Running Loss:  0.0004530126516922164\n",
      "Running Loss:  0.0004524446814314383\n",
      "Running Loss:  0.00045188384417501774\n",
      "Running Loss:  0.00045133003202380364\n",
      "Running Loss:  0.00045078313876347734\n",
      "Running Loss:  0.00045024305986146395\n",
      "Running Loss:  0.00044970969246258354\n",
      "Running Loss:  0.00044918293538334317\n",
      "Running Loss:  0.0004486626891048547\n",
      "Running Loss:  0.0004481488557643522\n",
      "Running Loss:  0.00044764133914530324\n",
      "Running Loss:  0.0004471400446661322\n",
      "Running Loss:  0.0004466448793675898\n",
      "Running Loss:  0.00044615575189882814\n",
      "Running Loss:  0.00044567257250219315\n",
      "Running Loss:  0.00044519525299688316\n",
      "Running Loss:  0.0004447237067614511\n",
      "Running Loss:  0.0004442578487153229\n",
      "Running Loss:  0.0004437975952993524\n",
      "Running Loss:  0.00044334286445551406\n",
      "Running Loss:  0.000442893575605857\n",
      "Running Loss:  0.0004424496496307561\n",
      "Running Loss:  0.0004420110088465758\n",
      "Running Loss:  0.00044157757698282785\n",
      "Running Loss:  0.0004411492791588959\n",
      "Running Loss:  0.00044072604186040805\n",
      "Running Loss:  0.0004403077929153347\n",
      "Running Loss:  0.0004398944614698723\n",
      "Running Loss:  0.0004394859779641789\n",
      "Running Loss:  0.00043908227410804473\n",
      "Running Loss:  0.0004386832828565117\n",
      "Running Loss:  0.00043828893838552754\n",
      "Running Loss:  0.0004378991760676746\n",
      "Running Loss:  0.00043751393244801344\n",
      "Running Loss:  0.0004371331452200686\n",
      "Running Loss:  0.00043675675320202864\n",
      "Running Loss:  0.00043638469631314267\n",
      "Running Loss:  0.00043601691555039375\n",
      "Running Loss:  0.0004356533529654303\n",
      "Running Loss:  0.00043529395164181224\n",
      "Running Loss:  0.00043493865567256984\n",
      "Running Loss:  0.0004345874101381047\n",
      "Running Loss:  0.0004342401610844444\n",
      "Running Loss:  0.00043389685550186257\n",
      "Running Loss:  0.0004335574413038832\n",
      "Running Loss:  0.0004332218673066616\n",
      "Running Loss:  0.0004328900832087725\n",
      "Running Loss:  0.0004325620395713898\n",
      "Running Loss:  0.000432237687798876\n",
      "Running Loss:  0.0004319169801197831\n",
      "Running Loss:  0.00043159986956826344\n",
      "Running Loss:  0.00043128630996588376\n",
      "Running Loss:  0.0004309762559038634\n",
      "Running Loss:  0.0004306696627257179\n",
      "Running Loss:  0.00043036648651031365\n",
      "Running Loss:  0.0004300666840553242\n",
      "Running Loss:  0.00042977021286109176\n",
      "Running Loss:  0.0004294770311148983\n",
      "Running Loss:  0.0004291870976756104\n",
      "Running Loss:  0.00042890037205873334\n",
      "Running Loss:  0.00042861681442184354\n",
      "Running Loss:  0.0004283363855503906\n",
      "Running Loss:  0.0004280590468438836\n",
      "Running Loss:  0.000427784760302444\n",
      "Running Loss:  0.0004275134885136965\n",
      "Running Loss:  0.00042724519464004636\n",
      "Running Loss:  0.00042697984240626385\n",
      "Running Loss:  0.0004267173960874426\n",
      "Running Loss:  0.00042645782049725286\n",
      "Running Loss:  0.0004262010809765436\n",
      "Running Loss:  0.00042594714338224345\n",
      "Running Loss:  0.0004256959740765751\n",
      "Running Loss:  0.000425447539916572\n",
      "Running Loss:  0.0004252018082438673\n",
      "Running Loss:  0.0004249587468747961\n",
      "Running Loss:  0.0004247183240907455\n",
      "Running Loss:  0.00042448050862878224\n",
      "Running Loss:  0.0004242452696725562\n",
      "Running Loss:  0.00042401257684342413\n",
      "Running Loss:  0.00042378240019184927\n",
      "Running Loss:  0.0004235547101890215\n",
      "Running Loss:  0.00042332947771871773\n",
      "Running Loss:  0.00042310667406937125\n",
      "Running Loss:  0.000422886270926381\n",
      "Running Loss:  0.00042266824036461104\n",
      "Running Loss:  0.0004224525548410978\n",
      "Running Loss:  0.0004222391871879643\n",
      "Running Loss:  0.0004220281106055094\n",
      "Running Loss:  0.00042181929865549355\n",
      "Running Loss:  0.00042161272525459594\n",
      "Running Loss:  0.00042140836466805055\n",
      "Running Loss:  0.00042120619150343906\n",
      "Running Loss:  0.0004210061807046547\n",
      "Running Loss:  0.00042080830754602077\n",
      "Running Loss:  0.0004206125476265523\n",
      "Running Loss:  0.00042041887686436816\n",
      "Running Loss:  0.0004202272714912513\n",
      "Running Loss:  0.00042003770804733274\n",
      "Running Loss:  0.00041985016337591256\n",
      "Running Loss:  0.00041966461461841176\n",
      "Running Loss:  0.00041948103920943835\n",
      "Running Loss:  0.00041929941487198484\n",
      "Running Loss:  0.00041911971961272604\n",
      "Running Loss:  0.0004189419317174385\n",
      "Running Loss:  0.000418766029746526\n",
      "Running Loss:  0.0004185919925306447\n",
      "Running Loss:  0.0004184197991664315\n",
      "Running Loss:  0.00041824942901232766\n",
      "Running Loss:  0.00041808086168450335\n",
      "Running Loss:  0.00041791407705286514\n",
      "Running Loss:  0.0004177490552371494\n",
      "Running Loss:  0.00041758577660311585\n",
      "Running Loss:  0.0004174242217588078\n",
      "Running Loss:  0.00041726437155089957\n",
      "Running Loss:  0.0004171062070611186\n",
      "Running Loss:  0.000416949709602749\n",
      "Running Loss:  0.0004167948607171996\n",
      "Running Loss:  0.00041664164217064526\n",
      "Running Loss:  0.0004164900359507436\n",
      "Running Loss:  0.0004163400242633995\n",
      "Running Loss:  0.0004161915895296235\n",
      "Running Loss:  0.00041604471438242075\n",
      "Running Loss:  0.00041589938166376397\n",
      "Running Loss:  0.0004157555744216112\n",
      "Running Loss:  0.00041561327590699073\n",
      "Running Loss:  0.0004154724695711357\n",
      "Running Loss:  0.0004153331390626731\n",
      "Running Loss:  0.0004151952682248687\n",
      "Running Loss:  0.000415058841092914\n",
      "Running Loss:  0.00041492384189128166\n",
      "Running Loss:  0.0004147902550311052\n",
      "Running Loss:  0.00041465806510762425\n",
      "Running Loss:  0.00041452725689766583\n",
      "Running Loss:  0.00041439781535717636\n",
      "Running Loss:  0.00041426972561879345\n",
      "Running Loss:  0.00041414297298945603\n",
      "Running Loss:  0.00041401754294806826\n",
      "Running Loss:  0.000413893421143189\n",
      "Running Loss:  0.00041377059339077325\n",
      "Running Loss:  0.00041364904567194066\n",
      "Running Loss:  0.0004135287641307883\n",
      "Running Loss:  0.0004134097350722425\n",
      "Running Loss:  0.000413291944959936\n",
      "Running Loss:  0.0004131753804141294\n",
      "Running Loss:  0.00041306002820966397\n",
      "Running Loss:  0.0004129458752739429\n",
      "Running Loss:  0.0004128329086849539\n",
      "Running Loss:  0.0004127211156693143\n",
      "Running Loss:  0.00041261048360035366\n",
      "Running Loss:  0.0004125009999962236\n",
      "Running Loss:  0.0004123926525180393\n",
      "Running Loss:  0.00041228542896804823\n",
      "Running Loss:  0.0004121793172878248\n",
      "Running Loss:  0.00041207430555650085\n",
      "Running Loss:  0.00041197038198901675\n",
      "Running Loss:  0.00041186753493439746\n",
      "Running Loss:  0.0004117657528740638\n",
      "Running Loss:  0.000411665024420161\n",
      "Running Loss:  0.00041156533831391163\n",
      "Running Loss:  0.0004114666834240004\n",
      "Running Loss:  0.0004113690487449803\n",
      "Running Loss:  0.00041127242339569596\n",
      "Running Loss:  0.0004111767966177365\n",
      "Running Loss:  0.00041108215777391677\n",
      "Running Loss:  0.0004109884963467628\n",
      "Running Loss:  0.0004108958019370413\n",
      "Running Loss:  0.00041080406426228925\n",
      "Running Loss:  0.0004107132731553845\n",
      "Running Loss:  0.00041062341856311867\n",
      "Running Loss:  0.0004105344905448099\n",
      "Running Loss:  0.0004104464792709078\n",
      "Running Loss:  0.00041035937502165523\n",
      "Running Loss:  0.00041027316818573363\n",
      "Running Loss:  0.00041018784925894866\n",
      "Running Loss:  0.00041010340884292874\n",
      "Running Loss:  0.00041001983764383593\n",
      "Running Loss:  0.0004099371264711094\n",
      "Running Loss:  0.00040985526623620776\n",
      "Running Loss:  0.0004097742479513824\n",
      "Running Loss:  0.00040969406272846364\n",
      "Running Loss:  0.00040961470177766336\n",
      "Running Loss:  0.00040953615640639066\n",
      "Running Loss:  0.00040945841801809407\n",
      "Running Loss:  0.0004093814781111054\n",
      "Running Loss:  0.0004093053282775088\n",
      "Running Loss:  0.0004092299602020244\n",
      "Running Loss:  0.00040915536566090696\n",
      "Running Loss:  0.00040908153652085053\n",
      "Running Loss:  0.00040900846473792337\n",
      "Running Loss:  0.00040893614235650353\n",
      "Running Loss:  0.000408864561508236\n",
      "Running Loss:  0.0004087937144110025\n",
      "Running Loss:  0.00040872359336790374\n",
      "Running Loss:  0.0004086541907662502\n",
      "Running Loss:  0.00040858549907658664\n",
      "Running Loss:  0.0004085175108516935\n",
      "Running Loss:  0.00040845021872563914\n",
      "Running Loss:  0.00040838361541282146\n",
      "Running Loss:  0.00040831769370702943\n",
      "Running Loss:  0.00040825244648051397\n",
      "Running Loss:  0.00040818786668307607\n",
      "Running Loss:  0.0004081239473411589\n",
      "Running Loss:  0.0004080606815569651\n",
      "Running Loss:  0.00040799806250756306\n",
      "Running Loss:  0.0004079360834440332\n",
      "Running Loss:  0.00040787473769059927\n",
      "Running Loss:  0.00040781401864378687\n",
      "Running Loss:  0.00040775391977158925\n",
      "Running Loss:  0.0004076944346126383\n",
      "Running Loss:  0.0004076355567753929\n",
      "Running Loss:  0.00040757727993733346\n",
      "Running Loss:  0.00040751959784417186\n",
      "Running Loss:  0.0004074625043090636\n",
      "Running Loss:  0.00040740599321183597\n",
      "Running Loss:  0.00040735005849822266\n",
      "Running Loss:  0.00040729469417911306\n",
      "Running Loss:  0.0004072398943298032\n",
      "Running Loss:  0.0004071856530892633\n",
      "Running Loss:  0.0004071319646594108\n",
      "Running Loss:  0.00040707882330439364\n",
      "Running Loss:  0.00040702622334988004\n",
      "Running Loss:  0.00040697415918236184\n",
      "Running Loss:  0.0004069226252484647\n",
      "Running Loss:  0.00040687161605426235\n",
      "Running Loss:  0.00040682112616460635\n",
      "Running Loss:  0.00040677115020246147\n",
      "Running Loss:  0.0004067216828482449\n",
      "Running Loss:  0.0004066727188391796\n",
      "Running Loss:  0.0004066242529686573\n",
      "Running Loss:  0.0004065762800855996\n",
      "Running Loss:  0.0004065287950938366\n",
      "Running Loss:  0.00040648179295148663\n",
      "Running Loss:  0.0004064352686703516\n",
      "Running Loss:  0.00040638921731530437\n",
      "Running Loss:  0.00040634363400371073\n",
      "Running Loss:  0.00040629851390482357\n",
      "Running Loss:  0.000406253852239213\n",
      "Running Loss:  0.00040620964427818797\n",
      "Running Loss:  0.0004061658853432338\n",
      "Running Loss:  0.00040612257080545095\n",
      "Running Loss:  0.0004060796960849976\n",
      "Running Loss:  0.0004060372566505509\n",
      "Running Loss:  0.00040599524801876094\n",
      "Running Loss:  0.00040595366575372187\n",
      "Running Loss:  0.000405912505466444\n",
      "Running Loss:  0.00040587176281432855\n",
      "Running Loss:  0.0004058314335006627\n",
      "Running Loss:  0.000405791513274106\n",
      "Running Loss:  0.00040575199792818365\n",
      "Running Loss:  0.0004057128833008017\n",
      "Running Loss:  0.0004056741652737494\n",
      "Running Loss:  0.0004056358397722145\n",
      "Running Loss:  0.00040559790276430775\n",
      "Running Loss:  0.00040556035026059257\n",
      "Running Loss:  0.0004055231783136101\n",
      "Running Loss:  0.00040548638301742365\n",
      "Running Loss:  0.00040544996050716236\n",
      "Running Loss:  0.000405413906958567\n",
      "Running Loss:  0.00040537821858754484\n",
      "Running Loss:  0.00040534289164973706\n",
      "Running Loss:  0.0004053079224400701\n",
      "Running Loss:  0.00040527330729234033\n",
      "Running Loss:  0.0004052390425787745\n",
      "Running Loss:  0.0004052051247096239\n",
      "Running Loss:  0.0004051715501327382\n",
      "Running Loss:  0.0004051383153331645\n",
      "Running Loss:  0.00040510541683273267\n",
      "Running Loss:  0.00040507285118966115\n",
      "Running Loss:  0.0004050406149981596\n",
      "Running Loss:  0.00040500870488803883\n",
      "Running Loss:  0.00040497711752431677\n",
      "Running Loss:  0.00040494584960684704\n",
      "Running Loss:  0.0004049148978699354\n",
      "Running Loss:  0.00040488425908196155\n",
      "Running Loss:  0.00040485393004501804\n",
      "Running Loss:  0.00040482390759454396\n",
      "Running Loss:  0.0004047941885989595\n",
      "Running Loss:  0.0004047647699593118\n",
      "Running Loss:  0.0004047356486089243\n",
      "Running Loss:  0.0004047068215130448\n",
      "Running Loss:  0.0004046782856685079\n",
      "Running Loss:  0.0004046500381033836\n",
      "Running Loss:  0.00040462207587664946\n",
      "Running Loss:  0.0004045943960778551\n",
      "Running Loss:  0.00040456699582679443\n",
      "Running Loss:  0.00040453987227317446\n",
      "Running Loss:  0.0004045130225963056\n",
      "Running Loss:  0.0004044864440047702\n",
      "Running Loss:  0.00040446013373612096\n",
      "Running Loss:  0.00040443408905656243\n",
      "Running Loss:  0.0004044083072606432\n",
      "Running Loss:  0.0004043827856709573\n",
      "Running Loss:  0.0004043575216378406\n",
      "Running Loss:  0.0004043325125390776\n",
      "Running Loss:  0.000404307755779604\n",
      "Running Loss:  0.00040428324879121725\n",
      "Running Loss:  0.0004042589890322882\n",
      "Running Loss:  0.0004042349739874869\n",
      "Running Loss:  0.00040421120116749024\n",
      "Running Loss:  0.00040418766810870993\n",
      "Running Loss:  0.00040416437237301837\n",
      "Running Loss:  0.00040414131154747684\n",
      "Running Loss:  0.00040411848324406843\n",
      "Running Loss:  0.0004040958850994353\n",
      "Running Loss:  0.00040407351477460805\n",
      "Running Loss:  0.00040405136995475617\n",
      "Running Loss:  0.0004040294483489268\n",
      "Running Loss:  0.000404007747689793\n",
      "Running Loss:  0.0004039862657334031\n",
      "Running Loss:  0.00040396500025892976\n",
      "Running Loss:  0.00040394394906843233\n",
      "Running Loss:  0.00040392310998660624\n",
      "Running Loss:  0.00040390248086054895\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(DSET)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size):\n\u001b[1;32m      5\u001b[0m     batch \u001b[38;5;241m=\u001b[39m DSET[i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m256\u001b[39m: (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m256\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      7\u001b[0m     Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch])\n\u001b[1;32m      8\u001b[0m     Y_hat \u001b[38;5;241m=\u001b[39m lm(X)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##Train With MiniBatch Gradient Descent\n",
    "for _ in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    for i in range(len(DSET)//batch_size):\n",
    "        batch = DSET[i*256: (i+1)*256]\n",
    "        X = np.array([x[0] for x in batch]).T\n",
    "        Y = np.array([x[1] for x in batch])\n",
    "        Y_hat = lm(X)\n",
    "        l, dW, dB = loss(X,Y_hat,Y)\n",
    "        lm.W -= lr*dW\n",
    "        lm.b -= lr*dB\n",
    "        running_loss += l\n",
    "    lr *= lr_decay\n",
    "    print(\"Running Loss: \", running_loss/len(DSET))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efed738b-7c91-4657-9cb6-145af2e59b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6223929]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode(str):\n",
    "    str = str.translate(str.maketrans('','',string.punctuation))\n",
    "    str = str.split()\n",
    "    wc = [0 for _ in range(len(vocab))]\n",
    "    for word in str:\n",
    "        if word in word_index:\n",
    "            wc[word_index[word]]+=1\n",
    "    return wc\n",
    "\n",
    "test = \" is a delicious cinematic\"\n",
    "x = np.array(encode(test)).reshape(-1, 1)\n",
    "lm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "782eeeb8-168c-447d-bb72-90dc869aeff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de298c17-0a98-4427-9540-42f97a28bc71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
